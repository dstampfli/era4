{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information can be found at the link below\n",
    "https://github.com/explodinggradients/ragas/blob/main/docs/getstarted/rag_testset_generation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get environment variables\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom is_finished_parser to capture Gemini generation completion signals\n",
    "# https://docs.ragas.io/en/stable/howtos/customizations/customize_models/#google-vertex\n",
    "\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "def gemini_is_finished_parser(response: LLMResult) -> bool:\n",
    "\tis_finished_list = []\n",
    "\tfor g in response.flatten():\n",
    "\t\tresp = g.generations[0][0]\n",
    "\n",
    "\t\t# Check generation_info first\n",
    "\t\tif resp.generation_info is not None:\n",
    "\t\t\tfinish_reason = resp.generation_info.get(\"finish_reason\")\n",
    "\t\t\tif finish_reason is not None:\n",
    "\t\t\t\tis_finished_list.append(\n",
    "\t\t\t\t\tfinish_reason in [\"STOP\", \"MAX_TOKENS\"]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t# Check response_metadata as fallback\n",
    "\t\tif isinstance(resp, ChatGeneration) and resp.message is not None:\n",
    "\t\t\tmetadata = resp.message.response_metadata\n",
    "\t\t\tif metadata.get(\"finish_reason\"):\n",
    "\t\t\t\tis_finished_list.append(\n",
    "\t\t\t\t\tmetadata[\"finish_reason\"] in [\"STOP\", \"MAX_TOKENS\"]\n",
    "\t\t\t\t)\n",
    "\t\t\telif metadata.get(\"stop_reason\"):\n",
    "\t\t\t\tis_finished_list.append(\n",
    "\t\t\t\t\tmetadata[\"stop_reason\"] in [\"STOP\", \"MAX_TOKENS\"] \n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t# If no finish reason found, default to True\n",
    "\t\tif not is_finished_list:\n",
    "\t\t\tis_finished_list.append(True)\n",
    "\n",
    "\treturn all(is_finished_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Unittest Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"docs/10k/html\", glob=\"**/*.html\", show_progress=True,)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ragas.io/en/stable/howtos/customizations/customize_models/#google-vertex \n",
    "# https://docs.ragas.io/en/v0.1.21/howtos/customisations/run_config.html\n",
    "\n",
    "import os\n",
    "\n",
    "import google\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "USE_GOOGLE = False\n",
    "\n",
    "if USE_GOOGLE:\n",
    "\tcreds, _ = google.auth.default(quota_project_id=os.environ[\"PROJECT_ID\"])\n",
    "\t\n",
    "\tllm = ChatVertexAI(credentials=creds, model_name=os.environ[\"GOOGLE_LLM_MODEL_NAME\"],)\n",
    "\tembeddings = VertexAIEmbeddings(credentials=creds, model_name=os.environ[\"GOOGLE_EMBEDDING_MODEL_NAME\"])\n",
    "\n",
    "\tllm = LangchainLLMWrapper(llm, is_finished_parser=gemini_is_finished_parser)\n",
    "\tembeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "\trun_config=RunConfig(max_workers=2)\n",
    "else:\n",
    "\tllm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\tembeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "\trun_config=RunConfig(max_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5714265ea784c1b834e459d361dfb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0e7abe5acb46268f476fec2575b09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b9537afb324aafbce01df629451823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21df582e5ac14758bfa608066888d07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78afdd0c91b4ab28a191cadf550848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9755bb0e2037451cb1743dd86cbadbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae2588f60ed44ff90fa82f5108e162b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65b10dae0634fc192486b57ba3908fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ea7d9e99de4c97a8be37fb6fa81afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wut is the Annual Report on Form 10-K?</td>\n",
       "      <td>[PART II Item 5. Market for Registrant’s Commo...</td>\n",
       "      <td>The Annual Report on Form 10-K contains forwar...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Uber utilize technology to enhance it...</td>\n",
       "      <td>[statements, such information may be limited o...</td>\n",
       "      <td>Uber utilizes a massive network, leading techn...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does revenue recognition for mobility serv...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ndollar value of transactions invoi...</td>\n",
       "      <td>Revenue recognition for mobility services is p...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key factors contributing to reven...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\ndollar value of transactions invoi...</td>\n",
       "      <td>The key factors contributing to revenue recogn...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do economic conditions in Egypt affect the...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nthereto had an adverse impact on o...</td>\n",
       "      <td>Economic conditions in Egypt can significantly...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What significant events related to security in...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2022, we settled our UK VAT disput...</td>\n",
       "      <td>In November 2021, Drizly obtained final court ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0             Wut is the Annual Report on Form 10-K?   \n",
       "1  How does Uber utilize technology to enhance it...   \n",
       "2  How does revenue recognition for mobility serv...   \n",
       "3  What are the key factors contributing to reven...   \n",
       "4  How do economic conditions in Egypt affect the...   \n",
       "5  What significant events related to security in...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [PART II Item 5. Market for Registrant’s Commo...   \n",
       "1  [statements, such information may be limited o...   \n",
       "2  [<1-hop>\\n\\ndollar value of transactions invoi...   \n",
       "3  [<1-hop>\\n\\ndollar value of transactions invoi...   \n",
       "4  [<1-hop>\\n\\nthereto had an adverse impact on o...   \n",
       "5  [<1-hop>\\n\\n2022, we settled our UK VAT disput...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The Annual Report on Form 10-K contains forwar...   \n",
       "1  Uber utilizes a massive network, leading techn...   \n",
       "2  Revenue recognition for mobility services is p...   \n",
       "3  The key factors contributing to revenue recogn...   \n",
       "4  Economic conditions in Egypt can significantly...   \n",
       "5  In November 2021, Drizly obtained final court ...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  multi_hop_abstract_query_synthesizer  \n",
       "3  multi_hop_abstract_query_synthesizer  \n",
       "4  multi_hop_specific_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "TESTSET_SIZE = 5\n",
    "\n",
    "query_distribution = default_query_distribution(llm)\n",
    "\n",
    "# Create the generator \n",
    "generator = TestsetGenerator(llm=llm, embedding_model=embeddings)\n",
    "              \n",
    "# Generate the testset\n",
    "testset = generator.generate_with_langchain_docs(docs, testset_size=TESTSET_SIZE, query_distribution = query_distribution,run_config=run_config)\n",
    "\n",
    "# Write the testet to disk\n",
    "file_name = \"unittest_testset.csv\" \n",
    "testset.to_csv(f\"testsets/{file_name}\")\n",
    "\n",
    "# Display the testset\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Full Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"docs/10k/html\"\n",
    "\n",
    "loader = DirectoryLoader(path=path, glob=\"**/*.html\", show_progress=True, )\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "TESTSET_SIZE = 50\n",
    "\n",
    "query_distribution = default_query_distribution(generator_llm)\n",
    "\n",
    "# Create the generator \n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "\n",
    "# Generate the testset\n",
    "testset = generator.generate_with_langchain_docs(docs, testset_size=TESTSET_SIZE, query_distribution=query_distribution,)\n",
    "\n",
    "# Write the testet to disk\n",
    "file_name = \"10k_testset.csv_\" + timestr\n",
    "testset.to_csv(f\"tesetsets/{file_name}\")\n",
    "\n",
    "# Display the testset\n",
    "testset.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
