{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "72f8eea04bca7944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# %pip install -r requirements.txt",
   "id": "bf8f2f70261e5a11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environment Variables",
   "id": "8c82114f34e68590"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get environment variables\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ],
   "id": "62036f02577fbf8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Google Colab Auth",
   "id": "2c49c4ba3825d3ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if running in Google Colab\n",
    "\n",
    "import sys\n",
    "\n",
    "# If running in Colab, use the permissions of the currently authenticated user\n",
    "if \"google.colab\" in sys.modules:\n",
    "\tprint('Running in Google Colab')\n",
    "\n",
    "\tfrom google.colab import auth\n",
    "\n",
    "\tauth.authenticate_user()\n",
    "\n",
    "# If not, set the GOOGLE_APPLICATION_CREDENTIALS to the service account credentials file\n",
    "else:\n",
    "\tprint(\"Running locally\")"
   ],
   "id": "95ebb6c27c15c328",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utilities\n",
   "id": "440b872d62fb2887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the utils module\n",
    "\n",
    "from utils import *"
   ],
   "id": "63f0c5cf023448a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG Engine",
   "id": "6a581dc2cbde2824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/rag-quickstart\n",
    "\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from vertexai import rag\n",
    "from vertexai.generative_models import GenerativeModel, Tool\n",
    "\n",
    "PROJECT_ID = os.environ[\"PROJECT_ID\"]\n",
    "LOCATION = os.environ[\"REGION\"]\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ],
   "id": "d2eba44b788ebbe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/use-embedding-models\n",
    "\n",
    "# Create RagCorpus\n",
    "# Configure embedding model, for example \"text-embedding-004\".\n",
    "embedding_model_config = rag.EmbeddingModelConfig(publisher_model=\"publishers/google/models/text-embedding-004\")\n",
    "\n",
    "backend_config = rag.RagVectorDbConfig(rag_embedding_model_config=embedding_model_config)\n",
    "\n",
    "rag_corpus = rag.create_corpus(\n",
    "    display_name=\"test3\",\n",
    "    backend_config=backend_config,\n",
    ")\n",
    "\n",
    "# List the rag corpus you just created\n",
    "# rag_corpus = rag.list_corpora()\n",
    "\n",
    "# Import Files to the RagCorpus\n",
    "corpus_name = rag_corpus.name\n",
    "print(corpus_name)\n",
    "\n",
    "transformation_config = rag.TransformationConfig(\n",
    "    chunking_config=rag.ChunkingConfig(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "paths = [\"gs://docs-10k/pdf\"]\n",
    "\n",
    "# Load from GCS bucket\n",
    "GCS_BUCKET = \"gs://docs-10k/pdf\"\n",
    "rag.import_files(\n",
    "    corpus_name=corpus_name,\n",
    "    paths=paths,\n",
    "    max_embedding_requests_per_min=1000,  # Optional\n",
    "    transformation_config=transformation_config, # Optional\n",
    ")\n",
    "\n",
    "# # Load from file\n",
    "# rag_file_lyft = rag.upload_file(\n",
    "#     corpus_name=rag_corpus.name,\n",
    "#     display_name=\"lyft.pdf\",\n",
    "#     description=\"Lyft 10K for 2023\",\n",
    "#     path=\"docs/10k/pdf/lyft.pdf\",\n",
    "#     transformation_config=transformation_config,\n",
    "# )\n",
    "#\n",
    "# rag_file_uber = rag.upload_file(\n",
    "#     corpus_name=rag_corpus.name,\n",
    "#     display_name=\"uber.pdf\",\n",
    "#     description=\"Uber 10K for 2023\",\n",
    "#     path=\"docs/10k/pdf/uber.pdf\",\n",
    "#     transformation_config=transformation_config,\n",
    "# )\n",
    "\n",
    "# Check that the corpus was created\n",
    "print(rag.list_corpora())\n",
    "\n",
    "# List the files in the rag corpus\n",
    "print(rag.list_files(corpus_name))\n",
    "\n",
    "# # Delete the corpus\n",
    "# rag.delete_corpus(rag_corpus.name)"
   ],
   "id": "47fcab32aa80bbf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Direct context retrieval\n",
    "rag_retrieval_config=rag.RagRetrievalConfig(\n",
    "    top_k=3,  # Optional\n",
    "    filter=rag.Filter(vector_distance_threshold=0.5)  # Optional\n",
    ")\n",
    "\n",
    "response = rag.retrieval_query(\n",
    "    rag_resources=[\n",
    "        rag.RagResource(\n",
    "            rag_corpus=corpus_name,\n",
    "            # Optional: supply IDs from `rag.list_files()`.\n",
    "            # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "        )\n",
    "    ],\n",
    "    text=\"What was Uber's revenue in 2023?\",\n",
    "    rag_retrieval_config=rag_retrieval_config,\n",
    ")\n",
    "print(response)"
   ],
   "id": "d0d3cca3e4913434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "questions = [\n",
    "    \"What is the annual revenue of Uber?\",\n",
    "\t\"What is the annual revenue of Lyft?\",\n",
    "\t\"How does Uber's revenue compare to Lyft's revenue?\",\n",
    "\t\"Summarize Lyft's risk factors as bullet points?\",\n",
    "    \"Who is the CEO of Uber and what was their largest source of revenue in 2023?\",\n",
    "]\n",
    "\n",
    "# Enhance generation\n",
    "# Create a RAG retrieval tool\n",
    "rag_retrieval_tool = Tool.from_retrieval(\n",
    "    retrieval=rag.Retrieval(\n",
    "        source=rag.VertexRagStore(\n",
    "            rag_resources=[\n",
    "                rag.RagResource(\n",
    "                    rag_corpus=corpus_name,  # Currently only 1 corpus is allowed.\n",
    "                    # Optional: supply IDs from `rag.list_files()`.\n",
    "                    # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "                )\n",
    "            ],\n",
    "            rag_retrieval_config=rag_retrieval_config,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "# Create a gemini model instance\n",
    "rag_model = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash-001\",\n",
    "    tools=[rag_retrieval_tool]\n",
    ")\n",
    "\n",
    "# Generate response\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    response = rag_model.generate_content(question)\n",
    "\t#display(Markdown(response.text))\n",
    "    print(response.text)\n"
   ],
   "id": "c7cc042e07c68558",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
